{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.api.API object at 0x108e8e828>\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \"fBKRihVu5bNj0ypeey39J8v6x\"\n",
    "consumer_secret = \"E4fkBQMCfO9WGg6ZDitWxFRAdWrjIPaL24RTNSpnTXIsfGdO6g\"\n",
    "\n",
    "access_token = \"1146388838534660096-iYJJ8NXMf16sNj0O6jd6HzsjvtjfVp\"\n",
    "access_token_secret = \"r16edV26xmYuxj1wyzOhgZnvqKcYjnXqxaMRcMv8nUk75\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "print(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_tweet(tweet) :\n",
    "    tweet_date = tweet['created_at']\n",
    "    ts = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet_date,'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "\n",
    "    tweet_id = tweet['id']\n",
    "    tweet_text = tweet['text']\n",
    "    if('extended_tweet' in tweet.keys()):\n",
    "        tweet_text = tweet['extended_tweet']['full_text']\n",
    "\n",
    "    user_id = tweet['user']['id']\n",
    "    followers_count = tweet['user']['followers_count']\n",
    "    friends_count = tweet['user']['friends_count']\n",
    "\n",
    "    user_mentions = tweet['entities']['user_mentions']\n",
    "    screen_names = [user_mention['screen_name'] for user_mention in user_mentions]\n",
    "    screen_name = tweet['user']['screen_name']\n",
    "    retweet_count = tweet['retweet_count']\n",
    "    favorite_count = tweet['favorite_count']\n",
    "    retweeted = tweet['retweeted']\n",
    "    tweet_row = {'date':ts,\n",
    "                 'tweet_id' : tweet_id,\n",
    "                 'user_id' : user_id,\n",
    "                 'followers_count' : followers_count,\n",
    "                 'friends_count' : friends_count,\n",
    "                 'user_mentions' : screen_names,\n",
    "                 'screen_name' : screen_name,\n",
    "                 'retweet_count' : retweet_count,\n",
    "                 'favorite_count' : favorite_count,\n",
    "                 'retweeted' : retweeted,\n",
    "                 'full_text':tweet_text}\n",
    "    return tweet_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref : https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201906130000\n",
      "201906132359\n",
      "{}\n",
      "web_request_count:  1\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIzMmM4YmU2ZjM0MTIwZWZhMWJmNjJiMzgyNTNjYmNmMjRhMmE0NmExZDdlZGJhODA3OTM4NmEyOWIwNzUyZmNjIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTIyNTQyMTg2NDU2Njc4NC0wIn0=\n",
      "web_request_count:  2\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiJhZjUzNzhkNGZhOTNiM2E2YTBhYjlmM2RmYTcyZjlhOTY5NWY3Y2E0OTc0ZjU3Mzk3Mjg0N2VmNzU4MmRmYWU2IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTIwNTQxNjM4NTAxNTgwOC0wIn0=\n",
      "web_request_count:  3\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiI2Njc0Mzc5OGU2NTI0Njk2NjVmZWFmODYzYTM3NWQxZDdmYTRiMDdjMTc3ZDM3YjI2MTcxM2JkNDk2NWI0ZTU5IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTE3ODk1MDA1NDEyMTQ3NC0wIn0=\n",
      "web_request_count:  4\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIyNmMyNzYwMGM3MWI1NmMwZmE4MTk2YjQxZWU4ZDUzMjViNjcyYTMyMGZhZmQ4Yjc5Y2MwNDA1YTE3ZDAyN2FjIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTE1NjYwNTUyODgxMzU2OC0wIn0=\n",
      "web_request_count:  5\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIzZDNiZjRhYjY2ZjljNDg1NmVkYzc4ZTNlYTM4MzBiMmI4OTEwZDlhOGVjNGE5Yjg0MjMyNzdlNjlkOWI5YTA1IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTExNzY1NzYyMDM0MDczNy0wIn0=\n",
      "web_request_count:  6\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIwYzMxNjdkMjU1NDU0NWMyNjk0M2FlOTg0NTAyYjU4M2M4ZWQyYWM4NDZkOGVjYjI1N2U5MTkwOGYwMjk5OWU0IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTA4NjU0NDk1Njg0NjA4MC0wIn0=\n",
      "web_request_count:  7\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiJhMmY4OWMxODc1ODlmMWRjZTFkZTA4NTZmMTRhMzk5YTYxMTM0ODc0YzQwOWYzODllYWQ0ODYxZDM4MzFmMmY0IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTA1MDM0MzI2MDU5ODI3NC0wIn0=\n",
      "web_request_count:  8\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIyODY3OWRlZDMzOTFhNTZlNTlmMGI2MGFjYjNiYjMyMmNkNWM1YmRjNzM2ZjljMjg2MDQwZDVmYjhlNWQ3N2Y5IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzODk3NzY0MzA3ODkwNTg1Ni0wIn0=\n",
      "web_request_count:  9\n",
      "status_code:  200\n",
      "(799, 11)\n",
      "201906140000\n",
      "201906142359\n",
      "{}\n",
      "web_request_count:  10\n",
      "status_code:  200\n",
      "(100, 11)\n",
      "201906150000\n",
      "201906152359\n",
      "(100, 11)\n",
      "201906160000\n",
      "201906162359\n",
      "(100, 11)\n",
      "201906170000\n",
      "201906172359\n",
      "(100, 11)\n",
      "201906180000\n",
      "201906182359\n",
      "(100, 11)\n",
      "201906190000\n",
      "201906192359\n",
      "(100, 11)\n",
      "201906200000\n",
      "201906202359\n",
      "(100, 11)\n",
      "201906210000\n",
      "201906212359\n",
      "(100, 11)\n",
      "201906220000\n",
      "201906222359\n",
      "(100, 11)\n",
      "201906230000\n",
      "201906232359\n",
      "(100, 11)\n",
      "201906240000\n",
      "201906242359\n",
      "(100, 11)\n",
      "201906250000\n",
      "201906252359\n",
      "(100, 11)\n",
      "201906260000\n",
      "201906262359\n",
      "(100, 11)\n",
      "201906270000\n",
      "201906272359\n",
      "(100, 11)\n",
      "201906280000\n",
      "201906282359\n",
      "(100, 11)\n",
      "201906290000\n",
      "201906292359\n",
      "(100, 11)\n"
     ]
    }
   ],
   "source": [
    "#Ref : https://medium.com/@poconnell732/acquiring-free-historical-geo-located-data-from-twitter-1f8f2821e9b1\n",
    "from TwitterAPI import TwitterAPI\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import timedelta, date\n",
    "\n",
    "api = TwitterAPI(consumer_key=consumer_key,\n",
    "                 consumer_secret=consumer_secret,\n",
    "                 access_token_key=access_token,\n",
    "                 access_token_secret=access_token_secret)\n",
    "PRODUCT = '30day' #Using 30day API\n",
    "LABEL = '30daysdev' # sandbox name\n",
    "web_request_count = 0\n",
    "                \n",
    "start_month_date = date(2019, 6, 13)\n",
    "end_month_date = date(2019, 6, 30)\n",
    "\n",
    "for date in daterange(start_month_date, end_month_date):\n",
    "    list_tweets = []\n",
    "    next_token = {}\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "    start_date = date_str + \"0000\"\n",
    "    end_date = date_str + \"2359\"\n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "    \n",
    "    while ((next_token is not None) and (web_request_count<10)):\n",
    "        print(next_token)\n",
    "        if not next_token :\n",
    "            req_dict = {'query' : '@swiggy_in OR @swiggyCares lang:en', 'fromDate': start_date, 'toDate': end_date,}\n",
    "        else :\n",
    "            req_dict['next'] = next_token\n",
    "        \n",
    "        web_request_count += 1\n",
    "        print('web_request_count: ', web_request_count)\n",
    "        req = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), req_dict)\n",
    "        print('status_code: ', req.status_code)\n",
    "        response = req.json()\n",
    "        if('next' in response.keys()):\n",
    "            next_token = response['next']\n",
    "        else :\n",
    "            next_token = None\n",
    "        \n",
    "        #print(response)\n",
    "        results = response['results']\n",
    "        with open('swiggy/json/' + date_str + '_' + str(web_request_count) + '.json', 'w+') as f:\n",
    "            json.dump(results, f)\n",
    "        \n",
    "        #print(results)\n",
    "        for tweet in results:\n",
    "            tweet_row = process_tweet(tweet)\n",
    "            list_tweets.append(tweet_row)\n",
    "        df = pd.DataFrame(list_tweets)\n",
    "    df.to_csv('swiggy/' + date_str + '.csv', index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201906130000\n",
      "201906132359\n",
      "{}\n",
      "web_request_count:  1\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiI1ZjdmYTE2OTViNTI2ODVhMjUzOGFhMGU5ZTRmZWVjMjBhYmQ4ODc5YmZjZTQ5ZGViNmUwNTkxNTY2MjViNWRhIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTIzNDg0OTk4MDUwMjAxNi0wIn0=\n",
      "web_request_count:  2\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIzNDIwYjkyMGM0MGY5ZDk1NDM0NjE3M2VhNGM5NmRkZmIwNTRhZmM3NDQxYjBhYzM0ODUzZjUyYzIyZmY2NTdjIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTIxOTE2Mjg2ODI2OTA1Ni0wIn0=\n",
      "web_request_count:  3\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiI5YjMzNWZlN2FhZWJmZjRhOTkyMDc1NDA0Mzc3ZWY3OTkyYTc5ZGY0NjRmNGNhMGY4NDI0NjExNGIxZGRmZjAzIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTIwNDQ2OTUzNzcyMjM2OC0wIn0=\n",
      "web_request_count:  4\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIwMGE0OWQ4ZTU3N2Y4OTRiZmFlM2Q4MGM4ZDMxYzM4YzFjNGYyNTNlNDYxNzA1MDE3YWYxODk5YTY2ZDMzN2Q4IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTE4NjUyMzcwODk2MDc2OS0wIn0=\n",
      "web_request_count:  5\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIxNDJkZjdlNmQ3NjU2NTA3YWVkYzJlY2FkMTJhNzI4MmJkYTlkYWMzNGQ4YjFlMzYxOTcyYmNmY2ZjZDJhNzA2IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTE2NDIwMDE5NjkwNzAwOC0wIn0=\n",
      "web_request_count:  6\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiIzMDcxMDkzYjMyOWVlNGZhMjM4MWEzZmIxOWZkZDA1ZDJjNmE3NGQ3ODkyNzc0OGQ1OTQ3ZDZkYTBlZjQ3YzhkIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTEzOTYzMjU0MzU5MjQ0OC0wIn0=\n",
      "web_request_count:  7\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiJiMjI2NDA3MWQ2Y2EyNjUzN2UyYTZmMzYyY2U3Y2E2ODM5OGY1MDY0NjRjY2FiNmE0ZDcyOTZhYzFmNTAyNGUyIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTEwNDA0NjI1MjM0MzI5Ni0wIn0=\n",
      "web_request_count:  8\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiJlYjdjOGQzNTVjMzU2MmIwNTQwMjI2ZGM2MTlmNzQ5OGQ2YjE4YmYxZmI5MTk0N2NiNGIzMWY0NmZlMzYzOWJhIiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTA3MTU2Mzc3OTYwMDM4NC0wIn0=\n",
      "web_request_count:  9\n",
      "status_code:  200\n",
      "eyJhdXRoZW50aWNpdHkiOiI1MDNlNTRjZWM5MTAzMzk2Y2ZjN2QzYTEwNzFlMDZmYjdiYWVhM2RkYzQ2NDdiODVlYjMxNWNjMThhMWVhYTI4IiwiZnJvbURhdGUiOiIyMDE5MDYxMzAwMDAiLCJ0b0RhdGUiOiIyMDE5MDYxMzIzNTkiLCJuZXh0IjoiMjAxOTA2MTMyMzU5MDAtMTEzOTAzMTExODc3MzA0NzI5Ni0wIn0=\n",
      "web_request_count:  10\n",
      "status_code:  200\n",
      "(980, 11)\n",
      "201906140000\n",
      "201906142359\n",
      "(980, 11)\n",
      "201906150000\n",
      "201906152359\n",
      "(980, 11)\n",
      "201906160000\n",
      "201906162359\n",
      "(980, 11)\n",
      "201906170000\n",
      "201906172359\n",
      "(980, 11)\n",
      "201906180000\n",
      "201906182359\n",
      "(980, 11)\n",
      "201906190000\n",
      "201906192359\n",
      "(980, 11)\n",
      "201906200000\n",
      "201906202359\n",
      "(980, 11)\n",
      "201906210000\n",
      "201906212359\n",
      "(980, 11)\n",
      "201906220000\n",
      "201906222359\n",
      "(980, 11)\n",
      "201906230000\n",
      "201906232359\n",
      "(980, 11)\n",
      "201906240000\n",
      "201906242359\n",
      "(980, 11)\n",
      "201906250000\n",
      "201906252359\n",
      "(980, 11)\n",
      "201906260000\n",
      "201906262359\n",
      "(980, 11)\n",
      "201906270000\n",
      "201906272359\n",
      "(980, 11)\n",
      "201906280000\n",
      "201906282359\n",
      "(980, 11)\n",
      "201906290000\n",
      "201906292359\n",
      "(980, 11)\n"
     ]
    }
   ],
   "source": [
    "#Ref : https://medium.com/@poconnell732/acquiring-free-historical-geo-located-data-from-twitter-1f8f2821e9b1\n",
    "from TwitterAPI import TwitterAPI\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import timedelta, date\n",
    "\n",
    "api = TwitterAPI(consumer_key=consumer_key,\n",
    "                 consumer_secret=consumer_secret,\n",
    "                 access_token_key=access_token,\n",
    "                 access_token_secret=access_token_secret)\n",
    "PRODUCT = '30day' #Using 30day API\n",
    "LABEL = '30daysdev' # sandbox name\n",
    "web_request_count = 0\n",
    "                \n",
    "start_month_date = date(2019, 6, 13)\n",
    "end_month_date = date(2019, 6, 30)\n",
    "\n",
    "for date in daterange(start_month_date, end_month_date):\n",
    "    list_tweets = []\n",
    "    next_token = {}\n",
    "    date_str = date.strftime(\"%Y%m%d\")\n",
    "    start_date = date_str + \"0000\"\n",
    "    end_date = date_str + \"2359\"\n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "    \n",
    "    while (next_token is not None) and (web_request_count<10):\n",
    "        print(next_token)\n",
    "        if not next_token :\n",
    "            req_dict = {'query' : '@zomatocare OR @zomatoIn lang:en', 'fromDate': start_date, 'toDate': end_date}\n",
    "        else :\n",
    "            req_dict['next'] = next_token\n",
    "        \n",
    "        web_request_count += 1\n",
    "        print('web_request_count: ', web_request_count)\n",
    "        req = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), req_dict)\n",
    "        print('status_code: ', req.status_code)\n",
    "        response = req.json()\n",
    "        if('next' in response.keys()):\n",
    "            next_token = response['next']\n",
    "        else :\n",
    "            next_token = None\n",
    "        \n",
    "        results = response['results']\n",
    "        with open('zomato/json/' + date_str + '_' + str(web_request_count) + '.json', 'w+') as f:\n",
    "            json.dump(results, f)\n",
    "        \n",
    "        #print(results)\n",
    "        for tweet in results:\n",
    "            tweet_row = process_tweet(tweet)\n",
    "            list_tweets.append(tweet_row)\n",
    "        df = pd.DataFrame(list_tweets)\n",
    "    df.to_csv('zomato/' + date_str + '.csv', index=False)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
